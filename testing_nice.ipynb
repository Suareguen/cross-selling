{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intento de mejora del anterior teniendo en cuenta lo que ha comprado el usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de órdenes después del filtrado: 134154\n",
      "Clientes únicos después del filtrado: 1000\n",
      "Productos únicos después del filtrado: 2193\n",
      "Órdenes por cliente (distribución):\n",
      "count    1000.000000\n",
      "mean      107.323000\n",
      "std        35.341869\n",
      "min         6.000000\n",
      "25%        95.750000\n",
      "50%       114.000000\n",
      "75%       129.000000\n",
      "max       195.000000\n",
      "dtype: float64\n",
      "Densidad de interacciones: 0.0290\n",
      "Tamaño de la matriz: (1000, 2193)\n",
      "Interacciones no nulas: 63534\n",
      "Modelo guardado en recommendation_model.pkl\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Conexión a MongoDB\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"my_database\"]\n",
    "orders_table = db[\"orders\"]\n",
    "products_table = db[\"products\"]\n",
    "\n",
    "# 1. Extraer datos de órdenes y productos con filtrado\n",
    "def extract_data(min_orders_per_user=5, min_users_per_product=5):\n",
    "    orders = list(orders_table.find({}, {\"Customer ID\": 1, \"Product ID\": 1, \"_id\": 0}))\n",
    "    orders_df = pd.DataFrame(orders)\n",
    "\n",
    "    products = list(products_table.find({}, {\"Product ID\": 1, \"Category\": 1, \"Name\": 1, \"_id\": 0}))\n",
    "    products_df = pd.DataFrame(products)\n",
    "\n",
    "    orders_with_categories = orders_df.merge(products_df, on=\"Product ID\")\n",
    "\n",
    "    # Filtrar usuarios con pocas órdenes\n",
    "    user_order_counts = orders_with_categories.groupby(\"Customer ID\").size()\n",
    "    valid_users = user_order_counts[user_order_counts >= min_orders_per_user].index\n",
    "    orders_with_categories = orders_with_categories[orders_with_categories[\"Customer ID\"].isin(valid_users)]\n",
    "\n",
    "    # Filtrar productos con pocas compras\n",
    "    product_order_counts = orders_with_categories.groupby(\"Product ID\").size()\n",
    "    valid_products = product_order_counts[product_order_counts >= min_users_per_product].index\n",
    "    orders_with_categories = orders_with_categories[orders_with_categories[\"Product ID\"].isin(valid_products)]\n",
    "\n",
    "    # Dividir en conjunto de entrenamiento y prueba\n",
    "    train_df = orders_with_categories.sample(frac=0.8, random_state=42)\n",
    "    test_df = orders_with_categories.drop(train_df.index)\n",
    "\n",
    "    # Análisis del dataset\n",
    "    print(f\"Total de órdenes después del filtrado: {len(orders_with_categories)}\")\n",
    "    print(f\"Clientes únicos después del filtrado: {orders_with_categories['Customer ID'].nunique()}\")\n",
    "    print(f\"Productos únicos después del filtrado: {orders_with_categories['Product ID'].nunique()}\")\n",
    "    print(f\"Órdenes por cliente (distribución):\")\n",
    "    print(train_df.groupby(\"Customer ID\").size().describe())\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "# 2. Crear matriz de usuario-producto\n",
    "def create_user_product_matrix(orders_with_categories):\n",
    "    user_encoder = LabelEncoder()\n",
    "    product_encoder = LabelEncoder()\n",
    "\n",
    "    orders_with_categories[\"User Index\"] = user_encoder.fit_transform(orders_with_categories[\"Customer ID\"])\n",
    "    orders_with_categories[\"Product Index\"] = product_encoder.fit_transform(orders_with_categories[\"Product ID\"])\n",
    "\n",
    "    num_users = orders_with_categories[\"User Index\"].nunique()\n",
    "    num_products = orders_with_categories[\"Product Index\"].nunique()\n",
    "    matrix = np.zeros((num_users, num_products))\n",
    "\n",
    "    for _, row in orders_with_categories.iterrows():\n",
    "        matrix[row[\"User Index\"], row[\"Product Index\"]] += 1\n",
    "\n",
    "    # Análisis de la matriz usuario-producto\n",
    "    density = np.count_nonzero(matrix) / (matrix.shape[0] * matrix.shape[1])\n",
    "    print(f\"Densidad de interacciones: {density:.4f}\")\n",
    "    print(f\"Tamaño de la matriz: {matrix.shape}\")\n",
    "    print(f\"Interacciones no nulas: {np.count_nonzero(matrix)}\")\n",
    "\n",
    "    return matrix, user_encoder, product_encoder, orders_with_categories\n",
    "\n",
    "# 3. Recomendar productos usando similitud de coseno\n",
    "def recommend_products(user_id, matrix, user_encoder, product_encoder, orders_with_categories, num_recommendations=5):\n",
    "    if user_id not in user_encoder.classes_:\n",
    "        print(f\"El usuario {user_id} no tiene datos suficientes para generar recomendaciones.\")\n",
    "        return [], []\n",
    "\n",
    "    user_index = user_encoder.transform([user_id])[0]\n",
    "    user_similarities = cosine_similarity(matrix)\n",
    "    similar_users = np.argsort(-user_similarities[user_index])\n",
    "\n",
    "    user_categories = orders_with_categories[orders_with_categories[\"Customer ID\"] == user_id][\"Category\"].unique()\n",
    "    candidate_products = orders_with_categories[orders_with_categories[\"Category\"].isin(user_categories)][\"Product Index\"].unique()\n",
    "\n",
    "    # Excluir productos ya comprados por el usuario\n",
    "    purchased_products = orders_with_categories[orders_with_categories[\"Customer ID\"] == user_id][\"Product Index\"].unique()\n",
    "    candidate_products = [product for product in candidate_products if product not in purchased_products]\n",
    "\n",
    "    # Recomendar productos basados en usuarios similares\n",
    "    scores = matrix[similar_users[1:], :].sum(axis=0)\n",
    "    max_score = scores.max() if scores.max() > 0 else 1\n",
    "    normalized_scores = [(i, scores[i] / max_score) for i in candidate_products if scores[i] > 0]\n",
    "    normalized_scores = sorted(normalized_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    product_mapping = orders_with_categories[[\"Product Index\", \"Product ID\", \"Name\"]].drop_duplicates()\n",
    "    product_mapping = product_mapping.set_index(\"Product Index\")\n",
    "\n",
    "    recommended_products = [\n",
    "        (product_mapping.loc[product[0], \"Product ID\"], product_mapping.loc[product[0], \"Name\"], round(product[1], 2))\n",
    "        for product in normalized_scores[:num_recommendations]\n",
    "    ]\n",
    "\n",
    "    user_purchases = orders_with_categories[orders_with_categories[\"Customer ID\"] == user_id][[\"Product ID\", \"Name\", \"Category\"]].drop_duplicates()\n",
    "\n",
    "    return recommended_products, user_purchases\n",
    "\n",
    "# 4. Guardar el modelo completo\n",
    "def save_model(matrix, user_encoder, product_encoder, orders_with_categories, file_path=\"recommendation_model.pkl\"):\n",
    "    model_data = {\n",
    "        \"matrix\": matrix,\n",
    "        \"user_encoder\": user_encoder,\n",
    "        \"product_encoder\": product_encoder,\n",
    "        \"orders_with_categories\": orders_with_categories,\n",
    "    }\n",
    "    with open(file_path, \"wb\") as file:\n",
    "        pickle.dump(model_data, file)\n",
    "    print(f\"Modelo guardado en {file_path}\")\n",
    "\n",
    "# Ejecutar el sistema de recomendación\n",
    "if __name__ == \"__main__\":\n",
    "    # Filtrar usuarios con pocas órdenes y productos con pocas compras\n",
    "    train_df, test_df = extract_data(min_orders_per_user=5, min_users_per_product=5)\n",
    "    matrix, user_encoder, product_encoder, orders_with_categories = create_user_product_matrix(train_df)\n",
    "\n",
    "    # Guardar el modelo al final del entrenamiento\n",
    "    save_model(matrix, user_encoder, product_encoder, orders_with_categories)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Con URI MongoDB Atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de órdenes después del filtrado: 135996\n",
      "Clientes únicos después del filtrado: 1000\n",
      "Productos únicos después del filtrado: 2172\n",
      "Órdenes por cliente (distribución):\n",
      "count    1000.000000\n",
      "mean      108.797000\n",
      "std        33.157582\n",
      "min         4.000000\n",
      "25%        97.000000\n",
      "50%       116.000000\n",
      "75%       130.000000\n",
      "max       177.000000\n",
      "dtype: float64\n",
      "Densidad de interacciones: 0.0299\n",
      "Tamaño de la matriz: (1000, 2172)\n",
      "Interacciones no nulas: 65003\n",
      "Modelo guardado en recommendation_model.pkl\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Conexión a MongoDB Atlas\n",
    "uri = \"mongodb+srv://Suarenguen:Lampara.1@suarenguen.ay1mt6g.mongodb.net/\"\n",
    "client = MongoClient(uri)\n",
    "\n",
    "# Seleccionar la base de datos y las colecciones\n",
    "db = client[\"my_database\"]  # Cambia el nombre de la base de datos si es necesario\n",
    "orders_table = db[\"orders\"]\n",
    "products_table = db[\"products\"]\n",
    "\n",
    "# 1. Extraer datos de órdenes y productos con filtrado\n",
    "def extract_data(min_orders_per_user=5, min_users_per_product=5):\n",
    "    orders = list(orders_table.find({}, {\"Customer ID\": 1, \"Product ID\": 1, \"_id\": 0}))\n",
    "    orders_df = pd.DataFrame(orders)\n",
    "\n",
    "    products = list(products_table.find({}, {\"Product ID\": 1, \"Category\": 1, \"Name\": 1, \"_id\": 0}))\n",
    "    products_df = pd.DataFrame(products)\n",
    "\n",
    "    orders_with_categories = orders_df.merge(products_df, on=\"Product ID\")\n",
    "\n",
    "    # Filtrar usuarios con pocas órdenes\n",
    "    user_order_counts = orders_with_categories.groupby(\"Customer ID\").size()\n",
    "    valid_users = user_order_counts[user_order_counts >= min_orders_per_user].index\n",
    "    orders_with_categories = orders_with_categories[orders_with_categories[\"Customer ID\"].isin(valid_users)]\n",
    "\n",
    "    # Filtrar productos con pocas compras\n",
    "    product_order_counts = orders_with_categories.groupby(\"Product ID\").size()\n",
    "    valid_products = product_order_counts[product_order_counts >= min_users_per_product].index\n",
    "    orders_with_categories = orders_with_categories[orders_with_categories[\"Product ID\"].isin(valid_products)]\n",
    "\n",
    "    # Dividir en conjunto de entrenamiento y prueba\n",
    "    train_df = orders_with_categories.sample(frac=0.8, random_state=42)\n",
    "    test_df = orders_with_categories.drop(train_df.index)\n",
    "\n",
    "    # Análisis del dataset\n",
    "    print(f\"Total de órdenes después del filtrado: {len(orders_with_categories)}\")\n",
    "    print(f\"Clientes únicos después del filtrado: {orders_with_categories['Customer ID'].nunique()}\")\n",
    "    print(f\"Productos únicos después del filtrado: {orders_with_categories['Product ID'].nunique()}\")\n",
    "    print(f\"Órdenes por cliente (distribución):\")\n",
    "    print(train_df.groupby(\"Customer ID\").size().describe())\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "# 2. Crear matriz de usuario-producto\n",
    "def create_user_product_matrix(orders_with_categories):\n",
    "    user_encoder = LabelEncoder()\n",
    "    product_encoder = LabelEncoder()\n",
    "\n",
    "    orders_with_categories[\"User Index\"] = user_encoder.fit_transform(orders_with_categories[\"Customer ID\"])\n",
    "    orders_with_categories[\"Product Index\"] = product_encoder.fit_transform(orders_with_categories[\"Product ID\"])\n",
    "\n",
    "    num_users = orders_with_categories[\"User Index\"].nunique()\n",
    "    num_products = orders_with_categories[\"Product Index\"].nunique()\n",
    "    matrix = np.zeros((num_users, num_products))\n",
    "\n",
    "    for _, row in orders_with_categories.iterrows():\n",
    "        matrix[row[\"User Index\"], row[\"Product Index\"]] += 1\n",
    "\n",
    "    # Análisis de la matriz usuario-producto\n",
    "    density = np.count_nonzero(matrix) / (matrix.shape[0] * matrix.shape[1])\n",
    "    print(f\"Densidad de interacciones: {density:.4f}\")\n",
    "    print(f\"Tamaño de la matriz: {matrix.shape}\")\n",
    "    print(f\"Interacciones no nulas: {np.count_nonzero(matrix)}\")\n",
    "\n",
    "    return matrix, user_encoder, product_encoder, orders_with_categories\n",
    "\n",
    "# 3. Recomendar productos usando similitud de coseno\n",
    "def recommend_products(user_id, matrix, user_encoder, product_encoder, orders_with_categories, num_recommendations=5):\n",
    "    if user_id not in user_encoder.classes_:\n",
    "        print(f\"El usuario {user_id} no tiene datos suficientes para generar recomendaciones.\")\n",
    "        return [], []\n",
    "\n",
    "    user_index = user_encoder.transform([user_id])[0]\n",
    "    user_similarities = cosine_similarity(matrix)\n",
    "    similar_users = np.argsort(-user_similarities[user_index])\n",
    "\n",
    "    user_categories = orders_with_categories[orders_with_categories[\"Customer ID\"] == user_id][\"Category\"].unique()\n",
    "    candidate_products = orders_with_categories[orders_with_categories[\"Category\"].isin(user_categories)][\"Product Index\"].unique()\n",
    "\n",
    "    # Excluir productos ya comprados por el usuario\n",
    "    purchased_products = orders_with_categories[orders_with_categories[\"Customer ID\"] == user_id][\"Product Index\"].unique()\n",
    "    candidate_products = [product for product in candidate_products if product not in purchased_products]\n",
    "\n",
    "    # Recomendar productos basados en usuarios similares\n",
    "    scores = matrix[similar_users[1:], :].sum(axis=0)\n",
    "    max_score = scores.max() if scores.max() > 0 else 1\n",
    "    normalized_scores = [(i, scores[i] / max_score) for i in candidate_products if scores[i] > 0]\n",
    "    normalized_scores = sorted(normalized_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    product_mapping = orders_with_categories[[\"Product Index\", \"Product ID\", \"Name\"]].drop_duplicates()\n",
    "    product_mapping = product_mapping.set_index(\"Product Index\")\n",
    "\n",
    "    recommended_products = [\n",
    "        (product_mapping.loc[product[0], \"Product ID\"], product_mapping.loc[product[0], \"Name\"], round(product[1], 2))\n",
    "        for product in normalized_scores[:num_recommendations]\n",
    "    ]\n",
    "\n",
    "    user_purchases = orders_with_categories[orders_with_categories[\"Customer ID\"] == user_id][[\"Product ID\", \"Name\", \"Category\"]].drop_duplicates()\n",
    "\n",
    "    return recommended_products, user_purchases\n",
    "\n",
    "# 4. Guardar el modelo completo\n",
    "def save_model(matrix, user_encoder, product_encoder, orders_with_categories, file_path=\"recommendation_model.pkl\"):\n",
    "    model_data = {\n",
    "        \"matrix\": matrix,\n",
    "        \"user_encoder\": user_encoder,\n",
    "        \"product_encoder\": product_encoder,\n",
    "        \"orders_with_categories\": orders_with_categories,\n",
    "    }\n",
    "    with open(file_path, \"wb\") as file:\n",
    "        pickle.dump(model_data, file)\n",
    "    print(f\"Modelo guardado en {file_path}\")\n",
    "\n",
    "# Ejecutar el sistema de recomendación\n",
    "if __name__ == \"__main__\":\n",
    "    # Filtrar usuarios con pocas órdenes y productos con pocas compras\n",
    "    train_df, test_df = extract_data(min_orders_per_user=5, min_users_per_product=5)\n",
    "    matrix, user_encoder, product_encoder, orders_with_categories = create_user_product_matrix(train_df)\n",
    "\n",
    "    # Guardar el modelo al final del entrenamiento\n",
    "    save_model(matrix, user_encoder, product_encoder, orders_with_categories)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
