{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@5: 0.93, Recall@5: 0.10\n",
      "Recomendaciones para el usuario 1f63eb5a-531d-4398-85c4-643deb6804de: [('0aff57c9-2036-4878-b4d1-eec4ac524757', 'Blue Dot Rolling Pizza Cutter', np.float64(10384.0)), ('98f4bdac-73c8-424e-9b96-efe0844aefe1', 'Jhondeal.com Wheel Pizza Cutter', np.float64(10282.0)), ('662d3b8f-ba4d-459f-9cd9-91ac837503c8', 'Mom Italy Wheel Pizza Cutter', np.float64(10273.0)), ('fa5ab25d-8ece-4b0f-b81a-1f1d0c64a46b', 'Made In China Rolling Pizza Cutter', np.float64(10264.0)), ('21c56d5f-f241-421f-8bad-c1938138ef02', 'Apex Rolling Pizza Cutter', np.float64(10207.0))]\n"
     ]
    }
   ],
   "source": [
    "# from pymongo import MongoClient\n",
    "# import pandas as pd\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# import numpy as np\n",
    "\n",
    "# # Conexión a MongoDB\n",
    "# client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "# db = client[\"my_database\"]\n",
    "# orders_table = db[\"orders\"]\n",
    "# products_table = db[\"products\"]\n",
    "\n",
    "# # 1. Extraer datos de órdenes y productos\n",
    "# def extract_data():\n",
    "#     # Extraer órdenes\n",
    "#     orders = list(orders_table.find({}, {\"Customer ID\": 1, \"Product ID\": 1, \"_id\": 0}))\n",
    "#     orders_df = pd.DataFrame(orders)\n",
    "    \n",
    "#     # Extraer productos (incluyendo categoría y nombre)\n",
    "#     products = list(products_table.find({}, {\"Product ID\": 1, \"Category\": 1, \"Name\": 1, \"_id\": 0}))\n",
    "#     products_df = pd.DataFrame(products)\n",
    "    \n",
    "#     # Unir productos con categorías y nombres\n",
    "#     orders_with_categories = orders_df.merge(products_df, on=\"Product ID\")\n",
    "\n",
    "#     # Dividir en entrenamiento y prueba\n",
    "#     train_df = orders_with_categories.sample(frac=0.8, random_state=42)\n",
    "#     test_df = orders_with_categories.drop(train_df.index)\n",
    "\n",
    "#     return train_df, test_df\n",
    "\n",
    "# # 2. Crear matriz de usuario-producto\n",
    "# def create_user_product_matrix(orders_with_categories):\n",
    "#     # Codificar IDs de usuarios y productos\n",
    "#     user_encoder = LabelEncoder()\n",
    "#     product_encoder = LabelEncoder()\n",
    "\n",
    "#     orders_with_categories[\"User Index\"] = user_encoder.fit_transform(orders_with_categories[\"Customer ID\"])\n",
    "#     orders_with_categories[\"Product Index\"] = product_encoder.fit_transform(orders_with_categories[\"Product ID\"])\n",
    "\n",
    "#     # Crear matriz dispersa usuario-producto\n",
    "#     num_users = orders_with_categories[\"User Index\"].nunique()\n",
    "#     num_products = orders_with_categories[\"Product Index\"].nunique()\n",
    "#     matrix = np.zeros((num_users, num_products))\n",
    "\n",
    "#     for _, row in orders_with_categories.iterrows():\n",
    "#         matrix[row[\"User Index\"], row[\"Product Index\"]] += 1  # Cuenta de interacciones\n",
    "\n",
    "#     return matrix, user_encoder, product_encoder, orders_with_categories\n",
    "\n",
    "# # 3. Recomendar productos usando similitud de coseno (con filtro de categorías)\n",
    "# def recommend_products(user_id, matrix, user_encoder, product_encoder, orders_with_categories, num_recommendations=10):\n",
    "#     # Verificar si el usuario existe\n",
    "#     if user_id not in user_encoder.classes_:\n",
    "#         print(f\"El usuario {user_id} no tiene datos suficientes para generar recomendaciones.\")\n",
    "#         return []\n",
    "\n",
    "#     user_index = user_encoder.transform([user_id])[0]\n",
    "\n",
    "#     # Calcular similitud entre usuarios\n",
    "#     user_similarities = cosine_similarity(matrix)\n",
    "#     similar_users = np.argsort(-user_similarities[user_index])  # Ordenar usuarios similares\n",
    "\n",
    "#     # Filtrar productos comprados por categorías del usuario\n",
    "#     user_categories = orders_with_categories[orders_with_categories[\"Customer ID\"] == user_id][\"Category\"].unique()\n",
    "#     candidate_products = orders_with_categories[orders_with_categories[\"Category\"].isin(user_categories)][\"Product Index\"].unique()\n",
    "\n",
    "#     # Recomendar productos basados en usuarios similares\n",
    "#     scores = matrix[similar_users[1:], :].sum(axis=0)  # Ignorar al propio usuario\n",
    "#     scores = [(i, scores[i]) for i in candidate_products if scores[i] > 0]\n",
    "#     scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "#     # Obtener los productos recomendados (ID y nombres)\n",
    "#     product_mapping = orders_with_categories[[\"Product Index\", \"Product ID\", \"Name\"]].drop_duplicates()\n",
    "#     product_mapping = product_mapping.set_index(\"Product Index\")\n",
    "\n",
    "#     recommended_products = [\n",
    "#         (product_mapping.loc[product[0], \"Product ID\"], product_mapping.loc[product[0], \"Name\"], product[1])\n",
    "#         for product in scores[:num_recommendations]\n",
    "#     ]\n",
    "#     return recommended_products\n",
    "\n",
    "# # 4. Evaluar el modelo\n",
    "# def evaluate_model(test_df, matrix, user_encoder, product_encoder, orders_with_categories, num_recommendations=5):\n",
    "#     precision_scores = []\n",
    "#     recall_scores = []\n",
    "#     all_recommendations = {}\n",
    "\n",
    "#     for user_id in test_df[\"Customer ID\"].unique():\n",
    "#         # Verificar si el usuario está en el conjunto de entrenamiento\n",
    "#         if user_id not in user_encoder.classes_:\n",
    "#             continue\n",
    "\n",
    "#         # Productos comprados en el conjunto de prueba\n",
    "#         relevant_products = test_df[test_df[\"Customer ID\"] == user_id][\"Product ID\"].unique()\n",
    "\n",
    "#         # Obtener recomendaciones\n",
    "#         recommendations = recommend_products(user_id, matrix, user_encoder, product_encoder, orders_with_categories, num_recommendations)\n",
    "#         recommended_products = [rec[0] for rec in recommendations]  # IDs de productos recomendados\n",
    "\n",
    "#         # Guardar recomendaciones por usuario\n",
    "#         all_recommendations[user_id] = recommendations\n",
    "\n",
    "#         # Calcular métricas\n",
    "#         relevant_recommended = set(recommended_products) & set(relevant_products)\n",
    "#         precision = len(relevant_recommended) / num_recommendations\n",
    "#         recall = len(relevant_recommended) / len(relevant_products) if len(relevant_products) > 0 else 0\n",
    "\n",
    "#         precision_scores.append(precision)\n",
    "#         recall_scores.append(recall)\n",
    "\n",
    "#     # Promediar métricas\n",
    "#     avg_precision = np.mean(precision_scores)\n",
    "#     avg_recall = np.mean(recall_scores)\n",
    "\n",
    "#     return avg_precision, avg_recall, all_recommendations\n",
    "\n",
    "# # Ejecutar el sistema de recomendación\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Extraer datos y construir la matriz usuario-producto\n",
    "#     train_df, test_df = extract_data()\n",
    "#     matrix, user_encoder, product_encoder, orders_with_categories = create_user_product_matrix(train_df)\n",
    "\n",
    "#     # Evaluar el modelo\n",
    "#     avg_precision, avg_recall, all_recommendations = evaluate_model(test_df, matrix, user_encoder, product_encoder, train_df, num_recommendations=5)\n",
    "#     print(f\"Precision@5: {avg_precision:.2f}, Recall@5: {avg_recall:.2f}\")\n",
    "\n",
    "#     # Mostrar recomendaciones para algunos usuarios\n",
    "#     for user_id, recommendations in list(all_recommendations.items())[:1]:  # Mostrar para un usuario\n",
    "#         print(f\"Recomendaciones para el usuario {user_id}: {recommendations}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codigo anterior con mejoras / Relevancia normalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@5: 0.27, Recall@5: 0.16\n",
      "\n",
      "Recomendaciones para el usuario 09ea6f56-580d-472a-b9e0-803b4c8583f3:\n",
      "                             Product ID  \\\n",
      "0  47f97163-3d02-49b3-896a-2632ccc811b7   \n",
      "1  b91a34eb-3530-442f-83c3-808dceb4b2af   \n",
      "2  af4f968c-2dfd-43af-b15c-2c824c01a775   \n",
      "3  07c70418-9916-46a4-96e0-dc821d034856   \n",
      "4  3b65dc65-2e8e-4988-91d5-e56288de12af   \n",
      "\n",
      "                                     Name  Relevancia  \n",
      "0   Blue Heaven Eyeliner (Set of 3) 21 ml        0.54  \n",
      "1  Organistick Silver Label Lipstick 10 g        0.53  \n",
      "2      Incolor Metalic Lipstick N15 3.8 g        0.47  \n",
      "3            Miss Lips Lipstick - 152 4 g        0.43  \n",
      "4            Miss Lips Lipstick - 138 4 g        0.42  \n",
      "--------------------------------------------------\n",
      "\n",
      "Productos comprados por el usuario 09ea6f56-580d-472a-b9e0-803b4c8583f3:\n",
      "                                  Product ID  \\\n",
      "121765  8da6f578-49cd-4deb-ba1a-fb2594a7ae88   \n",
      "114290  cbec1619-2653-4f67-991b-13f2fae38306   \n",
      "33544   486b70ce-cc11-420c-b18b-012f2b862e13   \n",
      "141558  478cbed3-6cc1-453c-9551-d554cbc61da0   \n",
      "75032   126cbd4b-b908-402b-9134-39849ef5c684   \n",
      "...                                      ...   \n",
      "128464  08df7880-695e-4b60-8428-fdae78298380   \n",
      "95464   dfb3df53-5f3b-45d2-946b-1804cb410235   \n",
      "24761   1a913954-78d9-4090-802a-9c58faeae613   \n",
      "46147   ce46af24-7002-40ef-88eb-84053f229b54   \n",
      "129040  4ffb4b42-4601-400b-ad04-59bc25469a18   \n",
      "\n",
      "                                                     Name  \\\n",
      "121765                    Wise Guys Pouch for Lenovo S880   \n",
      "114290  Legrand Legrand Arteor 573601 6A Indicator Mg ...   \n",
      "33544                        Denver Cool,Honour Combo Set   \n",
      "141558     Palakz Denim Pencil Pouch Art Cloth Pencil Box   \n",
      "75032   Ace HEADPHONE151ONTO Stereo Dynamic Headphone ...   \n",
      "...                                                   ...   \n",
      "128464                      Amore Abstract Cushions Cover   \n",
      "95464   www.thepaper.asia Flower Floral Art Canvas Pen...   \n",
      "24761                          BGS Alloy Crystal Bracelet   \n",
      "46147                    Indian Charm Beads Bone Necklace   \n",
      "129040                           Galz4ever Alloy Bracelet   \n",
      "\n",
      "                            Category  \n",
      "121765            Mobile Accessories  \n",
      "114290                   Electricals  \n",
      "33544                     Fragrances  \n",
      "141558               School Supplies  \n",
      "75032             Mobile Accessories  \n",
      "...                              ...  \n",
      "128464    Cushions, Pillows & Covers  \n",
      "95464                School Supplies  \n",
      "24761   Bangles, Bracelets & Armlets  \n",
      "46147             Necklaces & Chains  \n",
      "129040  Bangles, Bracelets & Armlets  \n",
      "\n",
      "[86 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# from pymongo import MongoClient\n",
    "# import pandas as pd\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# import numpy as np\n",
    "\n",
    "# # Conexión a MongoDB\n",
    "# client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "# db = client[\"my_database\"]\n",
    "# orders_table = db[\"orders\"]\n",
    "# products_table = db[\"products\"]\n",
    "\n",
    "# # 1. Extraer datos de órdenes y productos\n",
    "# def extract_data():\n",
    "#     orders = list(orders_table.find({}, {\"Customer ID\": 1, \"Product ID\": 1, \"_id\": 0}))\n",
    "#     orders_df = pd.DataFrame(orders)\n",
    "\n",
    "#     products = list(products_table.find({}, {\"Product ID\": 1, \"Category\": 1, \"Name\": 1, \"_id\": 0}))\n",
    "#     products_df = pd.DataFrame(products)\n",
    "\n",
    "#     orders_with_categories = orders_df.merge(products_df, on=\"Product ID\")\n",
    "#     train_df = orders_with_categories.sample(frac=0.8, random_state=42)\n",
    "#     test_df = orders_with_categories.drop(train_df.index)\n",
    "\n",
    "#     return train_df, test_df\n",
    "\n",
    "# # 2. Crear matriz de usuario-producto\n",
    "# def create_user_product_matrix(orders_with_categories):\n",
    "#     user_encoder = LabelEncoder()\n",
    "#     product_encoder = LabelEncoder()\n",
    "\n",
    "#     orders_with_categories[\"User Index\"] = user_encoder.fit_transform(orders_with_categories[\"Customer ID\"])\n",
    "#     orders_with_categories[\"Product Index\"] = product_encoder.fit_transform(orders_with_categories[\"Product ID\"])\n",
    "\n",
    "#     num_users = orders_with_categories[\"User Index\"].nunique()\n",
    "#     num_products = orders_with_categories[\"Product Index\"].nunique()\n",
    "#     matrix = np.zeros((num_users, num_products))\n",
    "\n",
    "#     for _, row in orders_with_categories.iterrows():\n",
    "#         matrix[row[\"User Index\"], row[\"Product Index\"]] += 1\n",
    "\n",
    "#     return matrix, user_encoder, product_encoder, orders_with_categories\n",
    "\n",
    "# # 3. Recomendar productos usando similitud de coseno\n",
    "# def recommend_products(user_id, matrix, user_encoder, product_encoder, orders_with_categories, num_recommendations=10):\n",
    "#     if user_id not in user_encoder.classes_:\n",
    "#         print(f\"El usuario {user_id} no tiene datos suficientes para generar recomendaciones.\")\n",
    "#         return [], []\n",
    "\n",
    "#     user_index = user_encoder.transform([user_id])[0]\n",
    "#     user_similarities = cosine_similarity(matrix)\n",
    "#     similar_users = np.argsort(-user_similarities[user_index])\n",
    "\n",
    "#     user_categories = orders_with_categories[orders_with_categories[\"Customer ID\"] == user_id][\"Category\"].unique()\n",
    "#     candidate_products = orders_with_categories[orders_with_categories[\"Category\"].isin(user_categories)][\"Product Index\"].unique()\n",
    "\n",
    "#     scores = matrix[similar_users[1:], :].sum(axis=0)\n",
    "#     max_score = scores.max() if scores.max() > 0 else 1  # Evitar división por 0\n",
    "#     normalized_scores = [(i, scores[i] / max_score) for i in candidate_products if scores[i] > 0]\n",
    "#     normalized_scores = sorted(normalized_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "#     product_mapping = orders_with_categories[[\"Product Index\", \"Product ID\", \"Name\"]].drop_duplicates()\n",
    "#     product_mapping = product_mapping.set_index(\"Product Index\")\n",
    "\n",
    "#     recommended_products = [\n",
    "#         (product_mapping.loc[product[0], \"Product ID\"], product_mapping.loc[product[0], \"Name\"], round(product[1], 2))\n",
    "#         for product in normalized_scores[:num_recommendations]\n",
    "#     ]\n",
    "\n",
    "#     user_purchases = orders_with_categories[orders_with_categories[\"Customer ID\"] == user_id][[\"Product ID\", \"Name\", \"Category\"]].drop_duplicates()\n",
    "\n",
    "#     return recommended_products, user_purchases\n",
    "\n",
    "# # 4. Evaluar el modelo\n",
    "# def evaluate_model(test_df, matrix, user_encoder, product_encoder, orders_with_categories, num_recommendations=5):\n",
    "#     precision_scores = []\n",
    "#     recall_scores = []\n",
    "#     all_recommendations = {}\n",
    "\n",
    "#     for user_id in test_df[\"Customer ID\"].unique():\n",
    "#         if user_id not in user_encoder.classes_:\n",
    "#             continue\n",
    "\n",
    "#         relevant_products = test_df[test_df[\"Customer ID\"] == user_id][\"Product ID\"].unique()\n",
    "\n",
    "#         recommendations, _ = recommend_products(user_id, matrix, user_encoder, product_encoder, orders_with_categories, num_recommendations)\n",
    "#         recommended_products = [rec[0] for rec in recommendations]\n",
    "\n",
    "#         all_recommendations[user_id] = recommendations\n",
    "\n",
    "#         relevant_recommended = set(recommended_products) & set(relevant_products)\n",
    "#         precision = len(relevant_recommended) / num_recommendations\n",
    "#         recall = len(relevant_recommended) / len(relevant_products) if len(relevant_products) > 0 else 0\n",
    "\n",
    "#         precision_scores.append(precision)\n",
    "#         recall_scores.append(recall)\n",
    "\n",
    "#     avg_precision = np.mean(precision_scores)\n",
    "#     avg_recall = np.mean(recall_scores)\n",
    "\n",
    "#     return avg_precision, avg_recall, all_recommendations\n",
    "\n",
    "# # Ejecutar el sistema de recomendación\n",
    "# if __name__ == \"__main__\":\n",
    "#     train_df, test_df = extract_data()\n",
    "#     matrix, user_encoder, product_encoder, orders_with_categories = create_user_product_matrix(train_df)\n",
    "\n",
    "#     avg_precision, avg_recall, all_recommendations = evaluate_model(test_df, matrix, user_encoder, product_encoder, train_df, num_recommendations=5)\n",
    "#     print(f\"Precision@5: {avg_precision:.2f}, Recall@5: {avg_recall:.2f}\")\n",
    "\n",
    "#     for user_id in test_df[\"Customer ID\"].unique()[:1]:\n",
    "#         recommendations, user_purchases = recommend_products(user_id, matrix, user_encoder, product_encoder, orders_with_categories, num_recommendations=5)\n",
    "#         print(f\"\\nRecomendaciones para el usuario {user_id}:\")\n",
    "#         print(pd.DataFrame(recommendations, columns=[\"Product ID\", \"Name\", \"Relevancia\"]))\n",
    "#         print(\"-\"*50)\n",
    "#         print(f\"\\nProductos comprados por el usuario {user_id}:\")\n",
    "#         print(user_purchases)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intento de mejora del anterior teniendo en cuenta lo que ha comprado el usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 113\u001b[0m\n\u001b[1;32m    110\u001b[0m train_df, test_df \u001b[38;5;241m=\u001b[39m extract_data()\n\u001b[1;32m    111\u001b[0m matrix, user_encoder, product_encoder, orders_with_categories \u001b[38;5;241m=\u001b[39m create_user_product_matrix(train_df)\n\u001b[0;32m--> 113\u001b[0m avg_precision, avg_recall, all_recommendations \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_encoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproduct_encoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_recommendations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision@10: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_precision\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Recall@10: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_recall\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m user_id \u001b[38;5;129;01min\u001b[39;00m test_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCustomer ID\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munique()[:\u001b[38;5;241m1\u001b[39m]:\n",
      "Cell \u001b[0;32mIn[35], line 91\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(test_df, matrix, user_encoder, product_encoder, orders_with_categories, num_recommendations)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     89\u001b[0m relevant_products \u001b[38;5;241m=\u001b[39m test_df[test_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCustomer ID\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m user_id][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProduct ID\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n\u001b[0;32m---> 91\u001b[0m recommendations, _ \u001b[38;5;241m=\u001b[39m \u001b[43mrecommend_products\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_encoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproduct_encoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morders_with_categories\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_recommendations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m recommended_products \u001b[38;5;241m=\u001b[39m [rec[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m rec \u001b[38;5;129;01min\u001b[39;00m recommendations]\n\u001b[1;32m     94\u001b[0m all_recommendations[user_id] \u001b[38;5;241m=\u001b[39m recommendations\n",
      "Cell \u001b[0;32mIn[35], line 51\u001b[0m, in \u001b[0;36mrecommend_products\u001b[0;34m(user_id, matrix, user_encoder, product_encoder, orders_with_categories, num_recommendations)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [], []\n\u001b[1;32m     50\u001b[0m user_index \u001b[38;5;241m=\u001b[39m user_encoder\u001b[38;5;241m.\u001b[39mtransform([user_id])[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 51\u001b[0m user_similarities \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m similar_users \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(\u001b[38;5;241m-\u001b[39muser_similarities[user_index])\n\u001b[1;32m     54\u001b[0m user_categories \u001b[38;5;241m=\u001b[39m orders_with_categories[orders_with_categories[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCustomer ID\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m user_id][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCategory\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n",
      "File \u001b[0;32m~/code/cross-selling/env/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m~/code/cross-selling/env/lib/python3.13/site-packages/sklearn/metrics/pairwise.py:1749\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1747\u001b[0m     Y_normalized \u001b[38;5;241m=\u001b[39m normalize(Y, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 1749\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_normalized\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdense_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m K\n",
      "File \u001b[0;32m~/code/cross-selling/env/lib/python3.13/site-packages/sklearn/utils/extmath.py:206\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m     ret \u001b[38;5;241m=\u001b[39m a \u001b[38;5;241m@\u001b[39m b\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m--> 206\u001b[0m     \u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43missparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    210\u001b[0m ):\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/code/cross-selling/env/lib/python3.13/site-packages/scipy/sparse/_base.py:1400\u001b[0m, in \u001b[0;36missparse\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"A namespace class to separate sparray from spmatrix\"\"\"\u001b[39;00m\n\u001b[1;32m   1397\u001b[0m sparray\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;241m=\u001b[39m _spbase\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m\n\u001b[0;32m-> 1400\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21missparse\u001b[39m(x):\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Is `x` of a sparse array or sparse matrix type?\u001b[39;00m\n\u001b[1;32m   1402\u001b[0m \n\u001b[1;32m   1403\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1429\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, _spbase)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from pymongo import MongoClient\n",
    "# import pandas as pd\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# import numpy as np\n",
    "\n",
    "# # Conexión a MongoDB\n",
    "# client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "# db = client[\"my_database\"]\n",
    "# orders_table = db[\"orders\"]\n",
    "# products_table = db[\"products\"]\n",
    "\n",
    "# # 1. Extraer datos de órdenes y productos\n",
    "# def extract_data():\n",
    "#     orders = list(orders_table.find({}, {\"Customer ID\": 1, \"Product ID\": 1, \"_id\": 0}))\n",
    "#     orders_df = pd.DataFrame(orders)\n",
    "\n",
    "#     products = list(products_table.find({}, {\"Product ID\": 1, \"Category\": 1, \"Name\": 1, \"_id\": 0}))\n",
    "#     products_df = pd.DataFrame(products)\n",
    "\n",
    "#     orders_with_categories = orders_df.merge(products_df, on=\"Product ID\")\n",
    "#     train_df = orders_with_categories.sample(frac=0.8, random_state=42)\n",
    "#     test_df = orders_with_categories.drop(train_df.index)\n",
    "\n",
    "#     return train_df, test_df\n",
    "\n",
    "# # 2. Crear matriz de usuario-producto\n",
    "# def create_user_product_matrix(orders_with_categories):\n",
    "#     user_encoder = LabelEncoder()\n",
    "#     product_encoder = LabelEncoder()\n",
    "\n",
    "#     orders_with_categories[\"User Index\"] = user_encoder.fit_transform(orders_with_categories[\"Customer ID\"])\n",
    "#     orders_with_categories[\"Product Index\"] = product_encoder.fit_transform(orders_with_categories[\"Product ID\"])\n",
    "\n",
    "#     num_users = orders_with_categories[\"User Index\"].nunique()\n",
    "#     num_products = orders_with_categories[\"Product Index\"].nunique()\n",
    "#     matrix = np.zeros((num_users, num_products))\n",
    "\n",
    "#     for _, row in orders_with_categories.iterrows():\n",
    "#         matrix[row[\"User Index\"], row[\"Product Index\"]] += 1\n",
    "\n",
    "#     return matrix, user_encoder, product_encoder, orders_with_categories\n",
    "\n",
    "# # 3. Recomendar productos usando similitud de coseno\n",
    "# def recommend_products(user_id, matrix, user_encoder, product_encoder, orders_with_categories, num_recommendations=5):\n",
    "#     if user_id not in user_encoder.classes_:\n",
    "#         print(f\"El usuario {user_id} no tiene datos suficientes para generar recomendaciones.\")\n",
    "#         return [], []\n",
    "\n",
    "#     user_index = user_encoder.transform([user_id])[0]\n",
    "#     user_similarities = cosine_similarity(matrix)\n",
    "#     similar_users = np.argsort(-user_similarities[user_index])\n",
    "\n",
    "#     user_categories = orders_with_categories[orders_with_categories[\"Customer ID\"] == user_id][\"Category\"].unique()\n",
    "#     candidate_products = orders_with_categories[orders_with_categories[\"Category\"].isin(user_categories)][\"Product Index\"].unique()\n",
    "\n",
    "#     # Excluir productos ya comprados por el usuario\n",
    "#     purchased_products = orders_with_categories[orders_with_categories[\"Customer ID\"] == user_id][\"Product Index\"].unique()\n",
    "#     candidate_products = [product for product in candidate_products if product not in purchased_products]\n",
    "\n",
    "#     # Recomendar productos basados en usuarios similares\n",
    "#     scores = matrix[similar_users[1:], :].sum(axis=0)\n",
    "#     max_score = scores.max() if scores.max() > 0 else 1\n",
    "#     normalized_scores = [(i, scores[i] / max_score) for i in candidate_products if scores[i] > 0]\n",
    "#     normalized_scores = sorted(normalized_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "#     product_mapping = orders_with_categories[[\"Product Index\", \"Product ID\", \"Name\"]].drop_duplicates()\n",
    "#     product_mapping = product_mapping.set_index(\"Product Index\")\n",
    "\n",
    "#     recommended_products = [\n",
    "#         (product_mapping.loc[product[0], \"Product ID\"], product_mapping.loc[product[0], \"Name\"], round(product[1], 2))\n",
    "#         for product in normalized_scores[:num_recommendations]\n",
    "#     ]\n",
    "\n",
    "#     user_purchases = orders_with_categories[orders_with_categories[\"Customer ID\"] == user_id][[\"Product ID\", \"Name\", \"Category\"]].drop_duplicates()\n",
    "\n",
    "#     return recommended_products, user_purchases\n",
    "\n",
    "# # 4. Evaluar el modelo\n",
    "# def evaluate_model(test_df, matrix, user_encoder, product_encoder, orders_with_categories, num_recommendations=10):\n",
    "#     precision_scores = []\n",
    "#     recall_scores = []\n",
    "#     all_recommendations = {}\n",
    "\n",
    "#     for user_id in test_df[\"Customer ID\"].unique():\n",
    "#         if user_id not in user_encoder.classes_:\n",
    "#             continue\n",
    "\n",
    "#         relevant_products = test_df[test_df[\"Customer ID\"] == user_id][\"Product ID\"].unique()\n",
    "\n",
    "#         recommendations, _ = recommend_products(user_id, matrix, user_encoder, product_encoder, orders_with_categories, num_recommendations)\n",
    "#         recommended_products = [rec[0] for rec in recommendations]\n",
    "\n",
    "#         all_recommendations[user_id] = recommendations\n",
    "\n",
    "#         relevant_recommended = set(recommended_products) & set(relevant_products)\n",
    "#         precision = len(relevant_recommended) / num_recommendations\n",
    "#         recall = len(relevant_recommended) / len(relevant_products) if len(relevant_products) > 0 else 0\n",
    "\n",
    "#         precision_scores.append(precision)\n",
    "#         recall_scores.append(recall)\n",
    "\n",
    "#     avg_precision = np.mean(precision_scores)\n",
    "#     avg_recall = np.mean(recall_scores)\n",
    "\n",
    "#     return avg_precision, avg_recall, all_recommendations\n",
    "\n",
    "# # Ejecutar el sistema de recomendación\n",
    "# if __name__ == \"__main__\":\n",
    "#     train_df, test_df = extract_data()\n",
    "#     matrix, user_encoder, product_encoder, orders_with_categories = create_user_product_matrix(train_df)\n",
    "\n",
    "#     avg_precision, avg_recall, all_recommendations = evaluate_model(test_df, matrix, user_encoder, product_encoder, train_df, num_recommendations=10)\n",
    "#     print(f\"Precision@10: {avg_precision:.2f}, Recall@10: {avg_recall:.2f}\")\n",
    "\n",
    "#     for user_id in test_df[\"Customer ID\"].unique()[:1]:\n",
    "#         recommendations, user_purchases = recommend_products(user_id, matrix, user_encoder, product_encoder, orders_with_categories, num_recommendations=10)\n",
    "#         print(f\"\\nRecomendaciones para el usuario {user_id}:\")\n",
    "#         print(pd.DataFrame(recommendations, columns=[\"Product ID\", \"Name\", \"Relevancia\"]))\n",
    "#         print(\"-\"*50)\n",
    "#         print(f\"\\nProductos comprados por el usuario {user_id}:\")\n",
    "#         print(user_purchases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de órdenes después del filtrado: 134154\n",
      "Clientes únicos después del filtrado: 1000\n",
      "Productos únicos después del filtrado: 2193\n",
      "Órdenes por cliente (distribución):\n",
      "count    1000.000000\n",
      "mean      107.323000\n",
      "std        35.341869\n",
      "min         6.000000\n",
      "25%        95.750000\n",
      "50%       114.000000\n",
      "75%       129.000000\n",
      "max       195.000000\n",
      "dtype: float64\n",
      "Densidad de interacciones: 0.0290\n",
      "Tamaño de la matriz: (1000, 2193)\n",
      "Interacciones no nulas: 63534\n",
      "Modelo guardado en recommendation_model.pkl\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Conexión a MongoDB\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"my_database\"]\n",
    "orders_table = db[\"orders\"]\n",
    "products_table = db[\"products\"]\n",
    "\n",
    "# 1. Extraer datos de órdenes y productos con filtrado\n",
    "def extract_data(min_orders_per_user=5, min_users_per_product=5):\n",
    "    orders = list(orders_table.find({}, {\"Customer ID\": 1, \"Product ID\": 1, \"_id\": 0}))\n",
    "    orders_df = pd.DataFrame(orders)\n",
    "\n",
    "    products = list(products_table.find({}, {\"Product ID\": 1, \"Category\": 1, \"Name\": 1, \"_id\": 0}))\n",
    "    products_df = pd.DataFrame(products)\n",
    "\n",
    "    orders_with_categories = orders_df.merge(products_df, on=\"Product ID\")\n",
    "\n",
    "    # Filtrar usuarios con pocas órdenes\n",
    "    user_order_counts = orders_with_categories.groupby(\"Customer ID\").size()\n",
    "    valid_users = user_order_counts[user_order_counts >= min_orders_per_user].index\n",
    "    orders_with_categories = orders_with_categories[orders_with_categories[\"Customer ID\"].isin(valid_users)]\n",
    "\n",
    "    # Filtrar productos con pocas compras\n",
    "    product_order_counts = orders_with_categories.groupby(\"Product ID\").size()\n",
    "    valid_products = product_order_counts[product_order_counts >= min_users_per_product].index\n",
    "    orders_with_categories = orders_with_categories[orders_with_categories[\"Product ID\"].isin(valid_products)]\n",
    "\n",
    "    # Dividir en conjunto de entrenamiento y prueba\n",
    "    train_df = orders_with_categories.sample(frac=0.8, random_state=42)\n",
    "    test_df = orders_with_categories.drop(train_df.index)\n",
    "\n",
    "    # Análisis del dataset\n",
    "    print(f\"Total de órdenes después del filtrado: {len(orders_with_categories)}\")\n",
    "    print(f\"Clientes únicos después del filtrado: {orders_with_categories['Customer ID'].nunique()}\")\n",
    "    print(f\"Productos únicos después del filtrado: {orders_with_categories['Product ID'].nunique()}\")\n",
    "    print(f\"Órdenes por cliente (distribución):\")\n",
    "    print(train_df.groupby(\"Customer ID\").size().describe())\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "# 2. Crear matriz de usuario-producto\n",
    "def create_user_product_matrix(orders_with_categories):\n",
    "    user_encoder = LabelEncoder()\n",
    "    product_encoder = LabelEncoder()\n",
    "\n",
    "    orders_with_categories[\"User Index\"] = user_encoder.fit_transform(orders_with_categories[\"Customer ID\"])\n",
    "    orders_with_categories[\"Product Index\"] = product_encoder.fit_transform(orders_with_categories[\"Product ID\"])\n",
    "\n",
    "    num_users = orders_with_categories[\"User Index\"].nunique()\n",
    "    num_products = orders_with_categories[\"Product Index\"].nunique()\n",
    "    matrix = np.zeros((num_users, num_products))\n",
    "\n",
    "    for _, row in orders_with_categories.iterrows():\n",
    "        matrix[row[\"User Index\"], row[\"Product Index\"]] += 1\n",
    "\n",
    "    # Análisis de la matriz usuario-producto\n",
    "    density = np.count_nonzero(matrix) / (matrix.shape[0] * matrix.shape[1])\n",
    "    print(f\"Densidad de interacciones: {density:.4f}\")\n",
    "    print(f\"Tamaño de la matriz: {matrix.shape}\")\n",
    "    print(f\"Interacciones no nulas: {np.count_nonzero(matrix)}\")\n",
    "\n",
    "    return matrix, user_encoder, product_encoder, orders_with_categories\n",
    "\n",
    "# 3. Recomendar productos usando similitud de coseno\n",
    "def recommend_products(user_id, matrix, user_encoder, product_encoder, orders_with_categories, num_recommendations=5):\n",
    "    if user_id not in user_encoder.classes_:\n",
    "        print(f\"El usuario {user_id} no tiene datos suficientes para generar recomendaciones.\")\n",
    "        return [], []\n",
    "\n",
    "    user_index = user_encoder.transform([user_id])[0]\n",
    "    user_similarities = cosine_similarity(matrix)\n",
    "    similar_users = np.argsort(-user_similarities[user_index])\n",
    "\n",
    "    user_categories = orders_with_categories[orders_with_categories[\"Customer ID\"] == user_id][\"Category\"].unique()\n",
    "    candidate_products = orders_with_categories[orders_with_categories[\"Category\"].isin(user_categories)][\"Product Index\"].unique()\n",
    "\n",
    "    # Excluir productos ya comprados por el usuario\n",
    "    purchased_products = orders_with_categories[orders_with_categories[\"Customer ID\"] == user_id][\"Product Index\"].unique()\n",
    "    candidate_products = [product for product in candidate_products if product not in purchased_products]\n",
    "\n",
    "    # Recomendar productos basados en usuarios similares\n",
    "    scores = matrix[similar_users[1:], :].sum(axis=0)\n",
    "    max_score = scores.max() if scores.max() > 0 else 1\n",
    "    normalized_scores = [(i, scores[i] / max_score) for i in candidate_products if scores[i] > 0]\n",
    "    normalized_scores = sorted(normalized_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    product_mapping = orders_with_categories[[\"Product Index\", \"Product ID\", \"Name\"]].drop_duplicates()\n",
    "    product_mapping = product_mapping.set_index(\"Product Index\")\n",
    "\n",
    "    recommended_products = [\n",
    "        (product_mapping.loc[product[0], \"Product ID\"], product_mapping.loc[product[0], \"Name\"], round(product[1], 2))\n",
    "        for product in normalized_scores[:num_recommendations]\n",
    "    ]\n",
    "\n",
    "    user_purchases = orders_with_categories[orders_with_categories[\"Customer ID\"] == user_id][[\"Product ID\", \"Name\", \"Category\"]].drop_duplicates()\n",
    "\n",
    "    return recommended_products, user_purchases\n",
    "\n",
    "# 4. Guardar el modelo completo\n",
    "def save_model(matrix, user_encoder, product_encoder, orders_with_categories, file_path=\"recommendation_model.pkl\"):\n",
    "    model_data = {\n",
    "        \"matrix\": matrix,\n",
    "        \"user_encoder\": user_encoder,\n",
    "        \"product_encoder\": product_encoder,\n",
    "        \"orders_with_categories\": orders_with_categories,\n",
    "    }\n",
    "    with open(file_path, \"wb\") as file:\n",
    "        pickle.dump(model_data, file)\n",
    "    print(f\"Modelo guardado en {file_path}\")\n",
    "\n",
    "# Ejecutar el sistema de recomendación\n",
    "if __name__ == \"__main__\":\n",
    "    # Filtrar usuarios con pocas órdenes y productos con pocas compras\n",
    "    train_df, test_df = extract_data(min_orders_per_user=5, min_users_per_product=5)\n",
    "    matrix, user_encoder, product_encoder, orders_with_categories = create_user_product_matrix(train_df)\n",
    "\n",
    "    # Guardar el modelo al final del entrenamiento\n",
    "    save_model(matrix, user_encoder, product_encoder, orders_with_categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
